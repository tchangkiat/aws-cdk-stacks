apiVersion: v1
kind: Namespace
metadata:
  name: example
  labels:
    pod-security.kubernetes.io/warn: restricted
    pod-security.kubernetes.io/warn-version: latest
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: web-app
  namespace: example
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: example
  name: web-app-amd64
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: web-app
      kubernetes.io/arch: amd64
  template:
    metadata:
      labels:
        app.kubernetes.io/name: web-app
        kubernetes.io/arch: amd64
    spec:
      automountServiceAccountToken: false
      securityContext:
        runAsUser: 65534
        runAsGroup: 65534
        fsGroup: 65534
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: web-app
      # This topology spread constraints configuration makes Karpenter to spread the nodes across all availability zones and spread the pods across all nodes evenly
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: web-app
              kubernetes.io/arch: amd64
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: ScheduleAnyway
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: web-app
              kubernetes.io/arch: amd64
      containers:
        - name: web-app
          image: [URL]
          imagePullPolicy: Always
          resources:
            limits:
              cpu: "0.5"
              memory: "1Gi"
            requests:
              cpu: "0.5"
              memory: "1Gi"
          # readinessProbe:
          #   httpGet:
          #     path: /
          #     port: 8000
          #   initialDelaySeconds: 10
          #   periodSeconds: 30
          #   timeoutSeconds: 3
          #   successThreshold: 1
          #   failureThreshold: 3
          # livenessProbe:
          #   httpGet:
          #     path: /
          #     port: 8000
          #   initialDelaySeconds: 10
          #   timeoutSeconds: 45
          #   periodSeconds: 120
          #   failureThreshold: 3
          ports:
            - containerPort: 8000
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
          env:
            - name: PATH_PREFIXES
              value: "/amd64,/canary"
            - name: GIN_MODE
              value: "release"
            - name: AWS_XRAY_SDK_DISABLED
              value: "TRUE"
            # Uncomment the next 4 lines if AWS X-Ray SDK is enabled
            # - name: AWS_XRAY_DAEMON_ADDRESS
            #   value: "xray-daemon.kube-system.svc.cluster.local:2100"
            # - name: AWS_XRAY_TRACING_NAME
            #   value: "web-app-amd64"
      nodeSelector:
        karpenter.sh/nodepool: default
        karpenter.sh/capacity-type: on-demand
        karpenter.k8s.aws/instance-family: c6i
---
apiVersion: v1
kind: Service
metadata:
  namespace: example
  name: web-app-amd64
spec:
  selector:
    app.kubernetes.io/name: web-app
    kubernetes.io/arch: amd64
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
  type: NodePort
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: example
  name: web-app-arm64
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: web-app
      kubernetes.io/arch: arm64
  template:
    metadata:
      labels:
        app.kubernetes.io/name: web-app
        kubernetes.io/arch: arm64
    spec:
      automountServiceAccountToken: false
      securityContext:
        runAsUser: 65534
        runAsGroup: 65534
        fsGroup: 65534
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: web-app
      # This topology spread constraints configuration makes Karpenter to spread the nodes across all availability zones and spread the pods across all nodes evenly
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: web-app
              kubernetes.io/arch: arm64
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: ScheduleAnyway
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: web-app
              kubernetes.io/arch: arm64
      containers:
        - name: web-app
          image: [URL]
          imagePullPolicy: Always
          resources:
            limits:
              cpu: "0.5"
              memory: "1Gi"
            requests:
              cpu: "0.5"
              memory: "1Gi"
          # readinessProbe:
          #   httpGet:
          #     path: /
          #     port: 8000
          #   initialDelaySeconds: 10
          #   periodSeconds: 30
          #   timeoutSeconds: 3
          #   successThreshold: 1
          #   failureThreshold: 3
          # livenessProbe:
          #   httpGet:
          #     path: /
          #     port: 8000
          #   initialDelaySeconds: 10
          #   timeoutSeconds: 45
          #   periodSeconds: 120
          #   failureThreshold: 3
          ports:
            - containerPort: 8000
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
          env:
            - name: PATH_PREFIXES
              value: "/arm64,/canary"
            - name: GIN_MODE
              value: "release"
            - name: AWS_XRAY_SDK_DISABLED
              value: "TRUE"
            # Uncomment the next 4 lines if AWS X-Ray SDK is enabled
            # - name: AWS_XRAY_DAEMON_ADDRESS
            #   value: "xray-daemon.kube-system.svc.cluster.local:2100"
            # - name: AWS_XRAY_TRACING_NAME
            #   value: "web-app-arm64"
      nodeSelector:
        karpenter.sh/nodepool: default-arm64
        karpenter.sh/capacity-type: on-demand
        karpenter.k8s.aws/instance-family: c7g
---
apiVersion: v1
kind: Service
metadata:
  namespace: example
  name: web-app-arm64
spec:
  selector:
    app.kubernetes.io/name: web-app
    kubernetes.io/arch: arm64
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
  type: NodePort
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  namespace: example
  name: web-app
  annotations:
    alb.ingress.kubernetes.io/load-balancer-name: web-app
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/actions.canary-deployment: >-
      {
        "type": "forward",
        "forwardConfig": {
          "targetGroups": [
            {
              "serviceName": "web-app-amd64",
              "servicePort": 8000,
              "weight": 90
            },
            {
              "serviceName": "web-app-arm64",
              "servicePort": 8000,
              "weight": 10
            }
          ]
        }
      }
spec:
  ingressClassName: alb
  rules:
    - http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: web-app-arm64
                port:
                  number: 8000
          - path: /amd64
            pathType: Prefix
            backend:
              service:
                name: web-app-amd64
                port:
                  number: 8000
          - path: /arm64
            pathType: Prefix
            backend:
              service:
                name: web-app-arm64
                port:
                  number: 8000
          - path: /canary
            pathType: Prefix
            backend:
              service:
                name: canary-deployment
                port:
                  name: use-annotation
